{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import languagecodes\n",
    "from collections import Counter\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "LANGCODE_MAPPING = {\n",
    "    'sw': 'swh',\n",
    "    'ar': 'arb',\n",
    "    'zh': 'cmn'\n",
    "}\n",
    "\n",
    "def get_iso_639_langcode(lang_code):\n",
    "    if lang_code in LANGCODE_MAPPING:\n",
    "        return LANGCODE_MAPPING[lang_code]\n",
    "    elif len(lang_code) == 2:\n",
    "        return languagecodes.iso_639_alpha3(lang_code)\n",
    "    else:\n",
    "        return lang_code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PanLex:\n",
    "    def __init__(self, panlex_dir, allow_space=False, min_quality=5):\n",
    "        self.panlex_dir = panlex_dir\n",
    "        self.allow_space = allow_space\n",
    "        self.min_quality = min_quality\n",
    "        self.cache_word = dict()\n",
    "\n",
    "        print('loadding langvar csv')\n",
    "        self.langvar = pd.read_csv(f'{panlex_dir}/langvar.csv')\n",
    "\n",
    "        print('loadding source csv')\n",
    "        source = pd.read_csv(f'{panlex_dir}/source.csv')\n",
    "        source['source'] = source.id\n",
    "        source = source[['source', 'quality']]\n",
    "        self.source = source\n",
    "\n",
    "        print('loadding expr csv')\n",
    "        self.expr = pd.read_csv(f'{panlex_dir}/expr.csv', usecols=['id', 'langvar', 'txt'])\n",
    "        \n",
    "        print('loadding meaning csv')\n",
    "        self.meaning = pd.read_csv(f'{panlex_dir}/meaning.csv')\n",
    "        \n",
    "        print('loadding denotation csv')\n",
    "        denotation = pd.read_csv(f'{panlex_dir}/denotation.csv', usecols=['meaning', 'expr'])\n",
    "        denotation['id'] = denotation.expr\n",
    "        del denotation['expr']\n",
    "        self.denotation = denotation\n",
    "        \n",
    "        print('finish setting up')\n",
    "\n",
    "    def get_langvar(self, lang_code, var_code=0):\n",
    "        langvar = self.langvar[(self.langvar.lang_code == lang_code) & (self.langvar.var_code == var_code)]\n",
    "        langvar = list(langvar.id)\n",
    "        assert len(langvar) == 1\n",
    "        return langvar[0]\n",
    "\n",
    "    def get_word(self, lang_code, var_code=0):\n",
    "        expr = self.expr\n",
    "        lang_code = get_iso_639_langcode(lang_code)\n",
    "        langvar = self.get_langvar(lang_code, var_code=var_code)\n",
    "        if langvar in self.cache_word:\n",
    "            return self.cache_word[langvar]\n",
    "        \n",
    "        print(f'loadding {lang_code} word')\n",
    "        word = expr[expr.langvar == langvar]\n",
    "        if not self.allow_space:\n",
    "            word = word[word.txt.str.contains(' ') == False]\n",
    "        word = pd.merge(word, self.meaning, how='inner', on='id')\n",
    "        word = pd.merge(word, self.source, how='inner', on='source')\n",
    "        del word['source']\n",
    "        word = pd.merge(word, self.denotation, how='inner', on='id')\n",
    "        \n",
    "        print(f'loaded {len(word)} words')\n",
    "        print('quality distribution:', Counter(word.quality))\n",
    "        word = word[word.quality >= self.min_quality]\n",
    "        self.cache_word[langvar] = word\n",
    "        return word\n",
    "\n",
    "    def get_dictionary(self, lang1, lang2):\n",
    "        word1 = self.get_word(lang1)\n",
    "        word2 = self.get_word(lang2)\n",
    "        print(f'building {lang1} & {lang2} dictionary')\n",
    "        # words with same meaning are translation (distance-1 translations)\n",
    "        dictionary = pd.merge(word1, word2, how='inner', on='meaning').dropna()\n",
    "        # slightly differ to how panlex measure quality (`tr1q`)\n",
    "        # https://dev.panlex.org/translation-evaluation/\n",
    "        dictionary['quality'] = dictionary.quality_x + dictionary.quality_y\n",
    "        dictionary = dictionary[['txt_x', 'txt_y', 'quality']]\n",
    "        dictionary = dictionary.groupby(['txt_x', 'txt_y']).agg({'quality': 'sum'}).reset_index()\n",
    "        print(f'total entry {lang1} & {lang2} = {len(dictionary)}')\n",
    "        return dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_dictionary(dictionary, filename):\n",
    "    with open(filename, 'w') as fp:\n",
    "        for l in dictionary.iterrows():\n",
    "            print(l[1].txt_x, l[1].txt_y, l[1].quality, sep='\\t', file=fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# If False, remove entry with space\n",
    "allow_space=False\n",
    "# Filter source with quality less than min_quality, scale is 0-9\n",
    "min_quality=5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loadding langvar csv\n",
      "loadding source csv\n",
      "loadding expr csv\n",
      "loadding meaning csv\n",
      "loadding denotation csv\n",
      "finish setting up\n"
     ]
    }
   ],
   "source": [
    "panlex = PanLex('./panlex-20211201-csv/',\n",
    "                allow_space=allow_space, min_quality=min_quality)\n",
    "directory = './data/'\n",
    "os.makedirs(directory, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "de\n",
      "es\n",
      "fr\n",
      "pl\n",
      "pt\n",
      "loadding por word\n",
      "loaded 673896 words\n",
      "quality distribution: Counter({5: 508784, 2: 133769, 3: 12459, 4: 8601, 7: 4912, 6: 2219, 8: 1990, 1: 565, 9: 534, 0: 63})\n",
      "da\n",
      "loadding dan word\n",
      "loaded 215636 words\n",
      "quality distribution: Counter({5: 155812, 3: 37262, 4: 12386, 7: 5663, 6: 1500, 9: 1405, 8: 567, 2: 555, 1: 373, 0: 113})\n",
      "it\n",
      "loadding ita word\n",
      "loaded 2056936 words\n",
      "quality distribution: Counter({5: 1078883, 7: 778773, 3: 103099, 2: 45578, 4: 27638, 1: 20789, 6: 1613, 9: 290, 8: 214, 0: 59})\n",
      "en\n",
      "loadding eng word\n",
      "loaded 10933993 words\n",
      "quality distribution: Counter({5: 10236105, 3: 393475, 4: 145939, 2: 100626, 7: 44989, 8: 5015, 6: 3773, 1: 2430, 9: 1380, 0: 261})\n"
     ]
    }
   ],
   "source": [
    "langs = 'de,es,fr,pl,pt,da,it,en'.split(',')\n",
    "for lang in langs:\n",
    "    print(lang)\n",
    "    _ = panlex.get_word(lang)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "de\n",
      "building de & en dictionary\n",
      "total entry de & en = 186704\n",
      "es\n",
      "building es & en dictionary\n",
      "total entry es & en = 179417\n",
      "fr\n",
      "building fr & en dictionary\n",
      "total entry fr & en = 335991\n",
      "pl\n",
      "building pl & en dictionary\n",
      "total entry pl & en = 99400\n",
      "pt\n",
      "building pt & en dictionary\n",
      "total entry pt & en = 199576\n",
      "da\n",
      "building da & en dictionary\n",
      "total entry da & en = 58524\n",
      "it\n",
      "building it & en dictionary\n",
      "total entry it & en = 315851\n",
      "en\n"
     ]
    }
   ],
   "source": [
    "trg = 'en'\n",
    "for src in langs:\n",
    "    print(src)\n",
    "    if src == 'en':\n",
    "        continue\n",
    "    dictionary = panlex.get_dictionary(src, trg)\n",
    "    filename = f'{directory}/{src}-{trg}.txt'\n",
    "    write_dictionary(dictionary, filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
